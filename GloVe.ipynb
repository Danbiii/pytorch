{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "random.seed(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "torch.cuda.set_device(gpus[0])\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data) #랜덤\n",
    "    sindex = 0 \n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size #추가추가\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "        \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'moby', 'dick', 'by', 'herman', 'melville', '1851', ']'], ['etymology', '.'], ['(', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', ')'], ['the', 'pale', 'usher', '--', 'threadbare', 'in', 'coat', ',', 'heart', ',', 'body', ',', 'and', 'brain', ';', 'i', 'see', 'him', 'now', '.'], ['he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', ',', 'with', 'a', 'queer', 'handkerchief', ',', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', '.']]\n"
     ]
    }
   ],
   "source": [
    "corpus = list(nltk. corpus.gutenberg.sents('melville-moby_dick.txt'))[:500]\n",
    "corpus = [[word.lower() for word in sent] for sent in corpus]\n",
    "print(corpus[0:5])  #소문자로 전환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attacks', 'pedestrians', 'hermit', 'perdition', 'vessels']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(flatten(corpus)))\n",
    "print(vocab[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "index2word = {v:k for k,v in word2index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<DUMMY>', '<DUMMY>', '<DUMMY>', '<DUMMY>', '<DUMMY>', '[', 'moby', 'dick', 'by', 'herman', 'melville')\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE=5\n",
    "windows = flatten([list(nltk.ngrams(['<DUMMY>'] * WINDOW_SIZE + c + \n",
    "                                  ['<DUMMY>']*WINDOW_SIZE, WINDOW_SIZE*2+1))\n",
    "                 for c in corpus])\n",
    "print(windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_data=[]\n",
    "for window in windows:\n",
    "    for i in range(WINDOW_SIZE*2+1):\n",
    "        if i == WINDOW_SIZE or window[i] == '<DUMMY>':\n",
    "            continue\n",
    "        window_data.append((window[WINDOW_SIZE], window[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i, w_j):\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1\n",
    "        \n",
    "    x_max = 100 #100: fixed in paper\n",
    "    alpha = 0.75\n",
    "    \n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha\n",
    "    else:\n",
    "        result = 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Co-occurence Matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = Counter(flatten(corpus)) #각 단어의 count 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ik_window_5 = Counter(window_data) #Co-occurence in window size 5\n",
    "## 각 window_data 갯수 >> window_data가 여러개 일수록 발생확률 up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ik = {}\n",
    "weighting_dic={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bigram in combinations_with_replacement(vocab,2):  #vocab: 소문자화 시킨 단어들\n",
    "    if X_ik_window_5.get(bigram) is not None: #nonzero elements\n",
    "        co_occer = X_ik_window_5[bigram]\n",
    "        X_ik[bigram] = co_occer + 1 #log(X_ik) -> log(X_ik+1) to prevent divergence\n",
    "        X_ik[(bigram[1], bigram[0])] = co_occer+1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1])\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('blanket', '?')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test = random.choice(window_data)\n",
    "print(test)\n",
    "try:\n",
    "    print(X_ik[(test[0], test[1])] == X_ik[(test[1], test[0])]) # 2\n",
    "except:\n",
    "    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] \n",
    "                    if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return Variable(LongTensor([word2index[word]]) \n",
    "                    if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_p = [] # 중심벡터\n",
    "v_p = [] # 주변벡터\n",
    "co_p = [] # log(X_ij)\n",
    "weight_p = [] # f(X_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 652\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      " 1412\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      ", Variable containing:\n",
      "1.00000e-02 *\n",
      "  5.3183\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for pair in window_data:\n",
    "    u_p.append(prepare_word(pair[0], word2index).view(1,-1))\n",
    "    v_p.append(prepare_word(pair[1], word2index).view(1,-1))\n",
    "    \n",
    "    try:\n",
    "        cooc = X_ik[pair] #동시발생확률?\n",
    "    except:\n",
    "        cooc = 1\n",
    "        \n",
    "    co_p.append(torch.log(Variable(FloatTensor([cooc]))).view(1,-1))\n",
    "    weight_p.append(Variable(FloatTensor([weighting_dic[pair]])).view(1,-1))\n",
    "    \n",
    "train_data = list(zip(u_p, v_p, co_p, weight_p))\n",
    "#del u_p\n",
    "#del v_p\n",
    "#del co_p\n",
    "#del weight_p\n",
    "print(train_data[0])  #tuple (중심벡터 i , 주변벡터 j log(X_ij), weight f(w_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, projection_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, projection_dim) #center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, projection_dim) #out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size,1) #center bias\n",
    "        self.u_bias = nn.Embedding(vocab_size,1) #context bias\n",
    "        \n",
    "        initrange = (6.0/ (vocab_size + projection_dim))**0.5 #Xavier init\n",
    "        self.embedding_v.weight.data.uniform_(-initrange, initrange) \n",
    "        self.embedding_u.weight.data.uniform_(-initrange, initrange) \n",
    "        self.v_bias.weight.data.uniform_(-initrange, initrange) \n",
    "        self.u_bias.weight.data.uniform_(-initrange, initrange) \n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weights):\n",
    "        center_embeds = self.embedding_v(center_words) # B X 1 X D\n",
    "        target_embeds = self.embedding_u(target_words) # B X 1 X D\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1,2)).squeeze(2) # B X 2\n",
    "        \n",
    "        loss = weights*torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
    "        #torch.pow -> input값에 exp를 취해 tensor로 결과값 반환\n",
    "        ##torch.pow(input, exponent, out=None) =>> 2 = exponent value\n",
    "        \n",
    "        return torch.sum(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        v_embeds = self.embedding_v(inputs) # B X 1 X D\n",
    "        u_embeds = self.embedding_u(inputs) # B X 1 X D\n",
    "        \n",
    "        return v_embeds + u_embeds #final embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "model = GloVe(len(word2index), EMBEDDING_SIZE)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, mean_loss : 119.20\n",
      "Epoch : 10, mean_loss : 1.18\n",
      "Epoch : 20, mean_loss : 0.06\n",
      "Epoch : 30, mean_loss : 0.03\n",
      "Epoch : 40, mean_loss : 0.02\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        \n",
    "        inputs, targets, coocs, weights = zip(*batch)\n",
    "        \n",
    "        inputs = torch.cat(inputs) # B X 1\n",
    "        targets = torch.cat(targets) # B X 1\n",
    "        coocs = torch.cat(coocs)\n",
    "        weights = torch.cat(weights)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = model(inputs, targets, coocs, weights)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.tolist()[0])\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch : %d, mean_loss : %.02f'%(epoch, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(target, vocab):\n",
    "    target_V = model.prediction(prepare_word(target, word2index))\n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(vocab)):\n",
    "        if vocab[i] == target:\n",
    "            continue\n",
    "            \n",
    "        vector = model.prediction(prepare_word(list(vocab)[i], word2index)) \n",
    "        cosine_sim = F.cosine_similarity(target_V, vector).data.tolist()[0]\n",
    "        similarities.append([vocab[i], cosine_sim])\n",
    "    return sorted(similarities, key = lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'against'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = random.choice(list(vocab))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['forty', 0.7925418615341187],\n",
       " ['set', 0.7201284170150757],\n",
       " ['call', 0.7059496641159058],\n",
       " ['one', 0.7039071321487427],\n",
       " ['sing', 0.7036358118057251],\n",
       " ['ruin', 0.697799563407898],\n",
       " ['limber', 0.6831038594245911],\n",
       " ['high', 0.6786397099494934],\n",
       " ['raphael', 0.6782793402671814],\n",
       " ['emigrant', 0.6740805506706238]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(test, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
